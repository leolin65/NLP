{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment02: Find Academic Keyword List\n",
    "Academic Keywords are the words we seldom use ordinarily, but often use in Academic articles. \"This shows\" and \"in conclusion\" are examples of Academic Keywords. This assignment want you to use Rank Ratio and compare two dataset to find Academic Keyword List(AKL).\n",
    "<br><br>\n",
    "One dataset is taken from [`British Academic Written English Corpus(BAWE)`](https://www.coventry.ac.uk/research/research-directories/current-projects/2015/british-academic-written-english-corpus-bawe/), which collect a record of proficient university-level student writing. Hence, BAWE can be seen as Academic data. Another one is called [`Web1T`](https://catalog.ldc.upenn.edu/LDC2006T13), which is presented by Google. Web1T colloct 1 trillion words of English Web, so we can treat it as the representative of common words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram counting\n",
    "This part is almost same as what you need to do in Assignment01. The way to find N-gram is the same as Assignment01. However, tokenization and calculating frequency are a little different. The rules of tokenization in this Assignment are:\n",
    " 1. Ignore case (e.g., \"The\" is the same as \"the\")\n",
    " 2. Split by white spaces <s>and punctuations</s>\n",
    " 3. Ignore all punctuation\n",
    "<br><br>\n",
    "\n",
    "As for calculating frequency, we want you calculating <u>document frequency</u> in this Assignment. <br>What is document frequency? \n",
    "<br>Article 1: \n",
    "> We all know that water masses in the ocean are thought to be transferred by the wind. ...\n",
    "\n",
    "Althought there are at least 2 \"the\" in Article 1, the document frequency of \"the\" is still 1 in this article.<br> No mater how many times does \"the\" show up in Article 1, the document frquency of it is always 1.<br>\n",
    "Article 2: \n",
    "> The film Dantes Peak is about a dormant volcano that suddenly erupts and threatens the nearby town. ...\n",
    "\n",
    "Considering the Article 1 and 2, the document frequency of \"the\" is 2 now.<br>\n",
    "Document frequency can reduce the influence of terms, like \"NLP\".\n",
    "<br><br>\n",
    "<span style=\"color: red\">[ TODO ]</span> Try to modify the functions coded in Assignment01 to <u>calculate document frequencies of all unigram.</u>.\n",
    "\n",
    "Google has calculated the frequency of N-gram, so you only need to do it on BAWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Having spent 10 half days and 3 full weeks at King Henry V111 school in Coventry I feel I can appreciate more what being a teacher is like, the challenges and every day tasks they face and how relevant some of the aspects of learning that we had studied were to the way the pupils there learnt. I spe\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join('data', 'BAWE.txt') # change to where you put your data\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    # [ TODO ] transform to lower case\n",
    "    text1 = re.findall(r'\\w+', text.lower()) #'[\\w]+|[,.]'  #'\\w+'  '[\\w]+|[,.?]'\n",
    "    \n",
    "    # [ TODO ] seperate the words\n",
    "    tokens = text.split(' ')\n",
    "    print(text[:90])\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Having spent 10 half days and 3 full weeks at King Henry V111 school in Coventry I feel I \n",
      "['Having', 'spent', '10', 'half', 'days', 'and', '3', 'full', 'weeks', 'at']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize(text)\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(tokens):\n",
    "    # [ TODO ]\n",
    "    frequency = Counter(tokens)\n",
    "    vocabulary_size = len(frequency.keys())\n",
    "    print('vocabulary_size:',vocabulary_size)\n",
    "    print(dict(frequency.most_common(100)))\n",
    "\n",
    "#    frequency = {...} \n",
    "    \"\"\"\n",
    "    Sample output: \n",
    "    {\n",
    "        'the': 79809, \n",
    "        'project': 288,\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = calculate_frequency(tokens)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(tokens, n=2):\n",
    "    # [ TODO ]\n",
    "    tokens = dict(tokens.most_common(n))\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Having spent 10 half days and 3 full weeks at King Henry V111 school in Coventry I feel I \n"
     ]
    }
   ],
   "source": [
    "\n",
    "BAWE_unigram = Counter(tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join('data', 'BAWE.txt') # change to where you put your data\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Web1T Data\n",
    "file_path = os.path.join('data', 'Web1T_unigram.txt')\n",
    "Web1T_unigram_counter = {}\n",
    "with open(file_path,'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        Web1T_unigram_counter[line[0]] = int(line[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank\n",
    "Rank unigrms by their frequencies. The higher the frequency, the higher the rank.(The most frequent unigram ranks 1.)<br>\n",
    "<span style=\"color: red\">[ TODO ]</span> <u>Rank unigrams for Web1T and BAWE.</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Web1T_unigram_Rank = calculate_frequency()\n",
    "#### [ TODO ] Rank unigrams for Web1T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAWE_unigram_Rank = calculate_frequency()\n",
    "#### [ TODO ] Rank unigrams for BAWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Rank Ratio\n",
    "In this step, you need to map the same unigram in two dataset, and caalculate the Rank Ratio of unigram in BAWE.  <br>Please follow the formula for calculating Rank Ratio:<br> \n",
    "<br>\n",
    "<img src=\"https://imgur.com/vmK7Q1K.jpg\" width=30%><br>\n",
    "If the unigram doesn't appear in Web1T, the rank of it is treated as 1.\n",
    "\n",
    "<span style=\"color: red\">[ TODO ]</span> Please calculate all rank ratios of unigrams in BAWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [TODO] calculate all rank ratios of unigrams in BAWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort the result\n",
    "<span style=\"color: red\">[ TODO ]</span> Please show top 30 uigrams in Rank Ratio and the value of their Rank Ratio in this format: \n",
    "<br>\n",
    "<img src=\"https://imgur.com/AEkiCRr.jpg\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [ TODO ] souw the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Bigrams\n",
    "<span style=\"color: red\">[ TODO ]</span> Do the Same Thing for Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TA's Notes\n",
    "\n",
    "If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1QGeYl5dsD9sFO9SYg4DIKk-xr-yGjRDOOLKZqCLDv2E/edit#gid=40492256) to reserve demo time.  \n",
    "The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to eeclass. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n",
    "<br>Note that **late submission will not be allowed**.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
